---
title: 大数据教程(二)-HDFS集群安装配置并附常用命令
date: 2019-11-08 10:54:05
categories: 大数据
tags: 
  - HDFS
  - linux
---
### 一、本篇教程侧重点导读
1. hadoop集群部署服务器规划；
2. hadoop安装包的下载解压；
3. 配置hadoop的系统环境变量；
4. 修改配置文件（主要四个文件：core-site.xml,hdfs-site.xml,hadoop-env.sh,worker）；
5. 初始化namenode节点；
6. 启动hdfs；
7. HDFS的其他配置项；
8. HDFS常用命令总结；

### 二、本篇教程用的软件、技术和说明
1. 承上启下，沿用第一篇大数据教程中的环境及软件；
2. hadoop安装包版本为：hadoop-3.2.1

### 三、hadoop集群部署服务器规划
计划在master（192.168.1.100）、slave（192.168.1.101）、slave2（192.168.1.102）上安装部署hadoop；
master节点上部署namenode
slave1、slave2节点上部署datanode
slave1上部署SecondaryNameNode节点

### 四、hadoop安装包的下载解压
hadoop官方网站：[**访问hadoop**](https://hadoop.apache.org "hadoop")
命令下载：`wget http://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz`
解压命令：`tar -xzvf hadoop-3.2.1.tar.gz -C /usr/local/`

### 五、配置hadoop的系统环境变量
修改文件 /etc/profile （<font color=red>三台机器都要修改</font>）
````bash
# 1.编辑文件
vim /etc/profile
# 2.文件底部增加以下内容：
# hadoop
HADOOP_HOME=/usr/local/hadoop-3.2.1
PATH=$HADOOP_HOME/bin:$PATH
export HADOOP_HOME PATH
# 3.刷新
source /etc/profile
````

### 六、修改配置文件
1. 修改配置文件：/usr/local/hadoop-3.2.1/etc/hadoop/core-site.xml （<font color=red>三台机器都要修改</font>）
````xml
	# 新增以下内容
	<property>
		<name>fs.defaultFS</name>
		<value>hdfs://master:10001</value> 
		<description>HDFS的URI，文件系统://namenode标识:端口</description>
	</property>
	<property>
		<name>hadoop.tmp.dir</name>
		<value>/usr/local/hadoop-3.2.1/tmp</value>
		<description>namenode上传到hadoop的临时文件夹</description>
	</property>
	<property>
		<name>fs.checkpoint.period</name>
		<value>3600</value>
		<description>用来设置检查点备份日志的最长时间</description>
	</property>
````
2. 修改配置文件：/usr/local/hadoop-3.2.1/etc/hadoop/hdfs-site.xml （<font color=red>三台机器都要修改</font>）
````xml
    # 新增以下内容
	<property>
		<name>dfs.replication</name>
		<value>3</value> 
		<description>副本个数，默认配置是3，应小于datanode机器数量</description>
	</property>
	<property>
		<name>dfs.name.dir</name>
		<value>/usr/local/hadoop-3.2.1/namenode</value>
		<description>namenode上存储hdfs名字空间元数据</description>
	</property>
	<property>
		<name>dfs.data.dir</name>
		<value>/usr/local/hadoop-3.2.1/datanode</value>
		<description>datanode上数据块的物理存储位置</description>
	</property>
````
3. 修改配置文件：/usr/local/hadoop-3.2.1/etc/hadoop/hadoop-env.sh （<font color=red>三台机器都要修改</font>）
````bash
    # 在文件末尾新增一行
	export JAVA_HOME=/usr/local/jdk1.8.0_161
````
4. 在master机器上修改文件（namenode节点）：/usr/local/hadoop-3.2.1/etc/hadoop/worker
````bash
    # 新增以下内容
	master
	slave1
	slave2
````

### 七、初始化namenode节点
 初始化命令：`hadoop namenode -format`

### 八、启动hdfs
启动HDFS集群命令`/usr/local/hadoop-3.2.1/sbin/start-dfs.sh`
**<font color=red>防坑</font>**：启动报错：
````
	Starting namenodes on [master]
	ERROR: Attempting to operate on hdfs namenode as root
	ERROR: but there is no HDFS_NAMENODE_USER defined. Aborting operation.
	Starting datanodes
	ERROR: Attempting to operate on hdfs datanode as root
	ERROR: but there is no HDFS_DATANODE_USER defined. Aborting operation.
	Starting secondary namenodes [master]
	ERROR: Attempting to operate on hdfs secondarynamenode as root
	ERROR: but there is no HDFS_SECONDARYNAMENODE_USER defined. Aborting operation.
````
**<font color=green>解决方案</font>**：
1. 修改配置文件：start-dfs.sh、stop-dfs.sh （<font color=red>三台机器都要修改</font>）
````bash
    vim /usr/local/hadoop-3.2.1/sbin/start-dfs.sh
	vim /usr/local/hadoop-3.2.1/sbin/stop-dfs.sh
	#在两个文件的顶部位置添加如下内容
	HDFS_DATANODE_USER=root
	HADOOP_SECURE_DN_USER=hdfs
	HDFS_NAMENODE_USER=root
	HDFS_SECONDARYNAMENODE_USER=root
````
2. 修改配置文件：start-yarn.sh、stop-yarn.sh （<font color=red>三台机器都要修改</font>）
````bash
    vim /usr/local/hadoop-3.2.1/sbin/start-yarn.sh
	vim /usr/local/hadoop-3.2.1/sbin/stop-yarn.sh
	#在两个文件的顶部位置添加如下内容
	YARN_RESOURCEMANAGER_USER=root
	HADOOP_SECURE_DN_USER=yarn
	YARN_NODEMANAGER_USER=root
````
<font color=green>备注：如果用其他账号启动HDFS，则所有root字符串位置替换成你的登陆用户名</font>
启动完成后，可以访问web页面：http://192.168.6.100:9870

### 九、HDFS的其他配置项
1. 默认配置时，SecondaryNameNode节点是会在namenode节点上启动的，如需指定的别的节点上启动，可在hdfs-site.xml中增加以下配置
````xml
	<!-- 配置secondaryNameNode -->
	<property>
		<name>dfs.namenode.secondary.http-address</name>
		<value>slave1:50090</value>
	</property>
````

### 十、HDFS常用命令总结
|序号|参数格式|参数含义|
|:-:|:---:|:---------:|
|1|hadoop fs -ls|显示当前目录结构，-ls -R 递归显示目录结构|
|2|hadoop fs -mkdir|创建目录|
|3|hadoop fs -rm|删除文件，-rm -R 递归删除目录和文件|
|4|hadoop fs -put [localsrc] [dst]|从本地加载文件到HDFS|
|5|hadoop fs -get [dst] [localsrc]|从HDFS导出文件到本地|
|6|hadoop fs - copyFromLocal [localsrc] [dst]|从本地加载文件到HDFS，与put一致|
|7|hadoop fs -copyToLocal [dst] [localsrc]|从HDFS导出文件到本地，与get一致|
|8|hadoop fs -test -e|检测目录和文件是否存在，存在返回值$?为0，不存在返回1|
|9|hadoop fs -text|查看文件内容|
|10|hadoop fs -du|统计目录下各文件大小，单位字节。-du -s 汇总目录下文件大小，-du -h 显示单位|
|11|hadoop fs -tail|显示文件末尾|
|12|hadoop fs -cp [src] [dst]|从源目录复制文件到目标目录|
|13|hadoop fs -mv [src] [dst]|从源目录移动文件到目标目录|

